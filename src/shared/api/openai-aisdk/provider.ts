/**
 * AI SDK OpenAI Provider
 * ä½¿ç”¨ @ai-sdk/openai å®ç°çš„ OpenAI ä¾›åº”å•†
 * ç»§æ‰¿è‡ª AbstractBaseProviderï¼Œä¸€æ¯”ä¸€å®ç° OpenAIProvider åŠŸèƒ½
 */
import { generateText } from 'ai';
import type { OpenAIProvider as AISDKOpenAIProvider } from '@ai-sdk/openai';
import { createClient, supportsMultimodal, supportsWebSearch, getWebSearchParams } from './client';
import { streamCompletion, nonStreamCompletion, type StreamResult } from './stream';
import { UnifiedParameterManager } from '../parameters/UnifiedParameterManager';
import { OpenAIParameterFormatter } from '../parameters/formatters';
import { isReasoningModel } from '../../../config/models';
import { AbstractBaseProvider } from '../baseProvider';
import type { Message, Model, MCPTool, MCPToolResponse, MCPCallToolResponse } from '../../types';
import { parseAndCallTools, parseToolUse, removeToolUseTags } from '../../utils/mcpToolParser';
import {
  convertMcpToolsToOpenAI,
  mcpToolCallResponseToOpenAIMessage,
  convertToolCallsToMcpResponses
} from './tools';
import { ChunkType, type Chunk } from '../../types/chunk';

/**
 * AI SDK OpenAI Provider åŸºç±»
 */
export abstract class BaseOpenAIAISDKProvider extends AbstractBaseProvider {
  protected client: AISDKOpenAIProvider;
  protected parameterManager: UnifiedParameterManager;

  constructor(model: Model) {
    super(model);
    this.client = createClient(model);
    this.parameterManager = new UnifiedParameterManager({ model, providerType: 'openai' });
  }

  /**
   * å°† MCP å·¥å…·è½¬æ¢ä¸º OpenAI å·¥å…·æ ¼å¼
   */
  public convertMcpTools<T>(mcpTools: MCPTool[]): T[] {
    return convertMcpToolsToOpenAI<T>(mcpTools);
  }

  /**
   * æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒå¤šæ¨¡æ€
   */
  protected supportsMultimodal(model?: Model): boolean {
    return supportsMultimodal(model || this.model);
  }

  /**
   * æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒç½‘é¡µæœç´¢
   */
  protected supportsWebSearch(): boolean {
    return supportsWebSearch(this.model);
  }

  /**
   * æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒæ¨ç†ä¼˜åŒ–
   */
  protected supportsReasoning(): boolean {
    return isReasoningModel(this.model);
  }

  /**
   * è·å–ç»Ÿä¸€å‚æ•°å¹¶è½¬æ¢ä¸º OpenAI API æ ¼å¼
   */
  protected getApiParams(assistant?: any): {
    unified: ReturnType<UnifiedParameterManager['getUnifiedParameters']>;
    apiParams: Record<string, any>;
  } {
    if (assistant) {
      this.parameterManager.updateAssistant(assistant);
    }
    const unified = this.parameterManager.getUnifiedParameters(isReasoningModel(this.model));
    const { customParameters, ...standardParams } = unified;
    const apiParams = OpenAIParameterFormatter.toAPIFormat(standardParams, this.model);
    
    // ğŸ†• åˆå¹¶è‡ªå®šä¹‰å‚æ•°åˆ° API è¯·æ±‚
    const finalParams = {
      ...apiParams,
      ...customParameters, // è‡ªå®šä¹‰å‚æ•°ç›´æ¥å±•å¼€åˆ°è¯·æ±‚ä¸­
    };
    
    return { unified, apiParams: finalParams };
  }

  /**
   * å‡†å¤‡ API æ¶ˆæ¯æ ¼å¼
   */
  protected async prepareAPIMessages(
    messages: Message[],
    systemPrompt?: string,
    mcpTools?: MCPTool[]
  ): Promise<any[]> {
    const apiMessages = [];

    // è·å–å·¥ä½œåŒºåˆ—è¡¨
    const workspaces = mcpTools && mcpTools.length > 0 ? await this.getWorkspaces() : [];

    // æ·»åŠ ç³»ç»Ÿæç¤º
    const finalSystemPrompt = this.buildSystemPromptWithTools(systemPrompt || '', mcpTools, workspaces);
    if (finalSystemPrompt.trim()) {
      apiMessages.push({
        role: 'system',
        content: finalSystemPrompt
      });
    }

    // å¤„ç†ç”¨æˆ·å’ŒåŠ©æ‰‹æ¶ˆæ¯ï¼ˆè·³è¿‡ system æ¶ˆæ¯ï¼Œå› ä¸ºå·²é€šè¿‡ buildSystemPromptWithTools åˆå¹¶ï¼‰
    for (const message of messages) {
      // è·³è¿‡ system æ¶ˆæ¯ï¼Œé¿å…é‡å¤
      if (message.role === 'system') {
        continue;
      }
      try {
        const content = (message as any).content;
        if (content !== undefined) {
          apiMessages.push({
            role: message.role,
            content: content
          });
        }
      } catch (error) {
        console.error(`[AI SDK Provider] å¤„ç†æ¶ˆæ¯å¤±è´¥:`, error);
        const content = (message as any).content;
        if (content && typeof content === 'string' && content.trim()) {
          apiMessages.push({
            role: message.role,
            content: content
          });
        }
      }
    }

    // ç¡®ä¿è‡³å°‘æœ‰ä¸€æ¡æ¶ˆæ¯
    if (apiMessages.length === 0 || !apiMessages.some(msg => msg.role === 'user')) {
      apiMessages.push({
        role: 'user',
        content: 'ä½ å¥½'
      });
    }

    return apiMessages;
  }

  /**
   * æµ‹è¯• API è¿æ¥
   */
  public async testConnection(): Promise<boolean> {
    try {
      // ä½¿ç”¨ .chat() è°ƒç”¨ Chat Completions APIï¼ˆå…¼å®¹ OpenAI å…¼å®¹ APIï¼‰
      const result = await generateText({
        model: this.client.chat(this.model.id) as any,
        prompt: 'Hello',
        maxOutputTokens: 5,
      });
      return Boolean(result.text);
    } catch (error) {
      console.error('[AI SDK Provider] API è¿æ¥æµ‹è¯•å¤±è´¥:', error);
      return false;
    }
  }

  /**
   * å°† MCP å·¥å…·è°ƒç”¨å“åº”è½¬æ¢ä¸ºæ¶ˆæ¯æ ¼å¼
   * @param useXmlFormat æ˜¯å¦ä½¿ç”¨ XML æ ¼å¼ï¼ˆæç¤ºè¯æ¨¡å¼ç”¨ trueï¼Œå‡½æ•°è°ƒç”¨æ¨¡å¼ç”¨ falseï¼‰
   */
  public mcpToolCallResponseToMessage(
    mcpToolResponse: MCPToolResponse,
    resp: MCPCallToolResponse,
    model: Model,
    useXmlFormat: boolean = false
  ): any {
    return mcpToolCallResponseToOpenAIMessage(mcpToolResponse, resp, model, useXmlFormat);
  }

  /**
   * å°†å·¥å…·è°ƒç”¨è½¬æ¢ä¸º MCP å·¥å…·å“åº”
   */
  protected convertToolCallsToMcpResponses(
    toolCalls: any[],
    mcpTools: MCPTool[]
  ): MCPToolResponse[] {
    return convertToolCallsToMcpResponses(toolCalls, mcpTools);
  }

  /**
   * æ£€æµ‹å·¥å…·åˆ—è¡¨æ˜¯å¦åŒ…å« attempt_completion
   */
  private hasCompletionTool(toolNames: string[]): boolean {
    return toolNames.some(name =>
      name === 'attempt_completion' || name.endsWith('-attempt_completion')
    );
  }

  /**
   * å¤„ç†å·¥å…·è°ƒç”¨ï¼ˆFunction Calling æ¨¡å¼ï¼‰
   */
  protected async processToolCalls(
    toolCalls: any[],
    mcpTools: MCPTool[],
    onChunk?: (chunk: Chunk) => void
  ): Promise<{ messages: any[]; hasCompletion: boolean }> {
    if (!toolCalls?.length) return { messages: [], hasCompletion: false };

    const toolNames = toolCalls.map(tc => tc.function?.name || tc.name || '');
    const hasCompletion = this.hasCompletionTool(toolNames);

    console.log(`[AI SDK Provider] å¤„ç† ${toolCalls.length} ä¸ªå·¥å…·è°ƒç”¨${hasCompletion ? 'ï¼ˆå« attempt_completionï¼‰' : ''}`);

    const mcpToolResponses = this.convertToolCallsToMcpResponses(toolCalls, mcpTools);
    const results = await parseAndCallTools(mcpToolResponses, mcpTools, onChunk);
    // å‡½æ•°è°ƒç”¨æ¨¡å¼ï¼šä½¿ç”¨ AI SDK çš„ ToolModelMessage æ ¼å¼ï¼ˆuseXmlFormat: falseï¼‰
    const messages = results
      .map((result, i) => this.mcpToolCallResponseToMessage(mcpToolResponses[i], result, this.model, false))
      .filter(Boolean);

    return { messages, hasCompletion };
  }

  /**
   * å¤„ç†å·¥å…·ä½¿ç”¨ï¼ˆXML æç¤ºè¯æ¨¡å¼ï¼‰
   */
  protected async processToolUses(
    content: string,
    mcpTools: MCPTool[],
    onChunk?: (chunk: Chunk) => void
  ): Promise<{ messages: any[]; hasCompletion: boolean }> {
    if (!content || !mcpTools?.length) return { messages: [], hasCompletion: false };

    const toolResponses = parseToolUse(content, mcpTools);
    if (!toolResponses.length) return { messages: [], hasCompletion: false };

    const toolNames = toolResponses.map(tr => tr.tool?.name || tr.tool?.id || '');
    const hasCompletion = this.hasCompletionTool(toolNames);

    console.log(`[AI SDK Provider] å¤„ç† ${toolResponses.length} ä¸ª XML å·¥å…·è°ƒç”¨${hasCompletion ? 'ï¼ˆå« attempt_completionï¼‰' : ''}`);

    const results = await parseAndCallTools(content, mcpTools, onChunk);
    const messages: any[] = [];

    // XML æç¤ºè¯æ¨¡å¼ï¼šä½¿ç”¨ user è§’è‰²çš„ XML æ ¼å¼æ¶ˆæ¯ï¼ˆuseXmlFormat: trueï¼‰
    for (let i = 0; i < Math.min(results.length, toolResponses.length); i++) {
      const msg = this.mcpToolCallResponseToMessage(toolResponses[i], results[i], this.model, true);
      if (msg) messages.push(msg);
    }

    return { messages, hasCompletion };
  }

  /**
   * æŠ½è±¡æ–¹æ³•ï¼šå‘é€èŠå¤©æ¶ˆæ¯
   */
  public abstract sendChatMessage(
    messages: Message[],
    options?: {
      onChunk?: (chunk: Chunk) => void;
      enableWebSearch?: boolean;
      systemPrompt?: string;
      enableTools?: boolean;
      mcpTools?: MCPTool[];
      mcpMode?: 'prompt' | 'function';
      abortSignal?: AbortSignal;
      assistant?: any;
    }
  ): Promise<string | { content: string; reasoning?: string; reasoningTime?: number }>;
}

/**
 * AI SDK OpenAI Provider å®ç°ç±»
 */
export class OpenAIAISDKProvider extends BaseOpenAIAISDKProvider {
  constructor(model: Model) {
    super(model);
    console.log(`[OpenAIAISDKProvider] åˆå§‹åŒ–å®Œæˆï¼Œæ¨¡å‹: ${model.id}`);
  }

  /**
   * å‘é€èŠå¤©æ¶ˆæ¯ - æ ¸å¿ƒ API è°ƒç”¨
   */
  public async sendChatMessage(
    messages: Message[],
    options?: {
      onChunk?: (chunk: Chunk) => void;
      enableWebSearch?: boolean;
      systemPrompt?: string;
      enableTools?: boolean;
      mcpTools?: MCPTool[];
      mcpMode?: 'prompt' | 'function';
      abortSignal?: AbortSignal;
      assistant?: any;
    }
  ): Promise<string | { content: string; reasoning?: string; reasoningTime?: number }> {
    console.log(`[OpenAIAISDKProvider] å¼€å§‹ API è°ƒç”¨, æ¨¡å‹: ${this.model.id}`);

    const {
      onChunk,
      enableWebSearch = false,
      systemPrompt = '',
      enableTools = true,
      mcpTools = [],
      mcpMode = 'function',
      abortSignal,
      assistant
    } = options || {};

    // å…ˆé…ç½®å·¥å…·ï¼ˆè®¾ç½® useSystemPromptForTools çš„å€¼ï¼‰
    // å¿…é¡»åœ¨ prepareAPIMessages ä¹‹å‰è°ƒç”¨ï¼Œå¦åˆ™ buildSystemPromptWithTools ä¼šä½¿ç”¨é”™è¯¯çš„é»˜è®¤å€¼
    const { tools } = this.setupToolsConfig({
      mcpTools,
      model: this.model,
      enableToolUse: enableTools,
      mcpMode
    });

    // å‡†å¤‡ API æ¶ˆæ¯æ ¼å¼ï¼ˆä¼šæ ¹æ® useSystemPromptForTools å†³å®šæ˜¯å¦æ³¨å…¥å·¥å…·æç¤ºè¯ï¼‰
    const apiMessages = await this.prepareAPIMessages(messages, systemPrompt, mcpTools);

    // è·å–ç»Ÿä¸€å‚æ•°ä¸ API æ ¼å¼å‚æ•°
    const { unified, apiParams } = this.getApiParams(assistant);
    const streamEnabled = unified.stream ?? true;

    console.log(`[OpenAIAISDKProvider] API è¯·æ±‚å‚æ•°:`, {
      model: this.model.id,
      apiParams,
      stream: streamEnabled,
      å·¥å…·æ•°é‡: tools.length
    });

    // æ£€æŸ¥ API å¯†é’¥
    if (!this.model.apiKey) {
      console.error('[OpenAIAISDKProvider] é”™è¯¯: API å¯†é’¥æœªè®¾ç½®');
      throw new Error('API å¯†é’¥æœªè®¾ç½®ï¼Œè¯·åœ¨è®¾ç½®ä¸­é…ç½® OpenAI API å¯†é’¥');
    }

    // æ·»åŠ ç½‘é¡µæœç´¢å‚æ•°
    const webSearchParams = enableWebSearch && this.supportsWebSearch()
      ? getWebSearchParams(this.model, enableWebSearch)
      : {};

    try {
      if (streamEnabled) {
        return await this.handleStreamResponse(apiMessages, {
          temperature: apiParams.temperature,
          maxTokens: apiParams.max_tokens,
          tools,
          mcpTools,
          mcpMode,
          onChunk,
          abortSignal,
          webSearchParams,
          extraBody: apiParams
        });
      } else {
        return await this.handleNonStreamResponse(apiMessages, {
          temperature: apiParams.temperature,
          maxTokens: apiParams.max_tokens,
          tools,
          mcpTools,
          mcpMode,
          onChunk,
          abortSignal,
          extraBody: apiParams
        });
      }
    } catch (error: any) {
      if (error?.name === 'AbortError' || error?.message?.includes('aborted')) {
        console.log('[OpenAIAISDKProvider] è¯·æ±‚è¢«ç”¨æˆ·ä¸­æ–­');
        throw new DOMException('Operation aborted', 'AbortError');
      }

      if (error?.status === 400 && error?.message?.includes('max_tokens')) {
        const modelName = this.model.name || this.model.id;
        throw new Error(`æ¨¡å‹ ${modelName} ä¸æ”¯æŒå½“å‰çš„æœ€å¤§è¾“å‡º token è®¾ç½® (${apiParams.max_tokens})ã€‚`);
      }

      console.error('[OpenAIAISDKProvider] API è¯·æ±‚å¤±è´¥:', error);
      throw error;
    }
  }

  /**
   * å¤„ç†æµå¼å“åº”
   */
  private async handleStreamResponse(
    messages: any[],
    options: {
      temperature?: number;
      maxTokens?: number;
      tools: any[];
      mcpTools: MCPTool[];
      mcpMode: 'prompt' | 'function';
      onChunk?: (chunk: Chunk) => void;
      abortSignal?: AbortSignal;
      webSearchParams?: any;
      extraBody?: Record<string, any>;
    }
  ): Promise<string | { content: string; reasoning?: string; reasoningTime?: number }> {
    const {
      temperature,
      maxTokens,
      tools,
      mcpTools,
      mcpMode,
      onChunk,
      abortSignal,
      extraBody
    } = options;

    let currentMessages = [...messages];
    let iteration = 0;
    const maxIterations = 10;

    while (iteration < maxIterations) {
      iteration++;
      console.log(`[OpenAIAISDKProvider] æµå¼å·¥å…·è°ƒç”¨è¿­ä»£ ${iteration}`);

      // å‡†å¤‡å·¥å…·é…ç½®
      const usePromptMode = this.getUseSystemPromptForTools();
      const streamTools = usePromptMode ? [] : tools;

      const result: StreamResult = await streamCompletion(
        this.client,
        this.model.id,
        currentMessages,
        temperature,
        maxTokens,
        {
          signal: abortSignal,
          enableTools: !usePromptMode && tools.length > 0,
          mcpTools,
          mcpMode,
          model: this.model,
          tools: streamTools,
          extraBody
        },
        onChunk
      );

      // æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
      if (result.hasToolCalls) {
        console.log(`[OpenAIAISDKProvider] æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨`);

        const content = result.content;
        const nativeToolCalls = result.nativeToolCalls;

        if (usePromptMode) {
          // æç¤ºè¯æ¨¡å¼ï¼šXML æ ¼å¼å·¥å…·è°ƒç”¨
          const { messages: xmlToolResults, hasCompletion } = await this.processToolUses(
            content,
            mcpTools,
            onChunk
          );

          if (xmlToolResults.length > 0) {
            currentMessages.push({ role: 'assistant', content });
            currentMessages.push(...xmlToolResults);

            if (hasCompletion) {
              console.log(`[OpenAIAISDKProvider] attempt_completion å·²æ‰§è¡Œ`);
              return this.formatResult(result);
            }
            continue;
          }
        } else if (nativeToolCalls && nativeToolCalls.length > 0) {
          // å‡½æ•°è°ƒç”¨æ¨¡å¼ï¼šä½¿ç”¨ AI SDK æœŸæœ›çš„ AssistantModelMessage æ ¼å¼
          const toolCallParts = nativeToolCalls.map((tc: any) => {
            let input = tc.function?.arguments || tc.args || {};
            if (typeof input === 'string') {
              try {
                input = JSON.parse(input);
              } catch {
                input = {};
              }
            }
            return {
              type: 'tool-call' as const,
              toolCallId: tc.id || tc.toolCallId,
              toolName: tc.function?.name || tc.name || tc.toolName,
              input
            };
          });
          
          const assistantContent = content 
            ? [{ type: 'text' as const, text: content }, ...toolCallParts]
            : toolCallParts;
          
          currentMessages.push({
            role: 'assistant',
            content: assistantContent
          });

          const { messages: toolResults, hasCompletion } = await this.processToolCalls(
            nativeToolCalls,
            mcpTools,
            onChunk
          );

          if (toolResults.length > 0) {
            currentMessages.push(...toolResults);

            if (hasCompletion) {
              console.log(`[OpenAIAISDKProvider] attempt_completion å·²æ‰§è¡Œ`);
              return this.formatResult(result);
            }
            continue;
          }
        }
      }

      // æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¿”å›ç»“æœ
      return this.formatResult(result);
    }

    console.warn(`[OpenAIAISDKProvider] è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° ${maxIterations}`);
    return '';
  }

  /**
   * å¤„ç†éæµå¼å“åº”
   */
  private async handleNonStreamResponse(
    messages: any[],
    options: {
      temperature?: number;
      maxTokens?: number;
      tools: any[];
      mcpTools: MCPTool[];
      mcpMode: 'prompt' | 'function';
      onChunk?: (chunk: Chunk) => void;
      abortSignal?: AbortSignal;
      extraBody?: Record<string, any>;
    }
  ): Promise<string | { content: string; reasoning?: string; reasoningTime?: number }> {
    const {
      temperature,
      maxTokens,
      tools,
      mcpTools,
      mcpMode,
      onChunk,
      abortSignal,
      extraBody
    } = options;

    let currentMessages = [...messages];
    let iteration = 0;
    const maxIterations = 5;
    let allReasoningParts: string[] = [];

    while (iteration < maxIterations) {
      iteration++;

      const usePromptMode = this.getUseSystemPromptForTools();
      const streamTools = usePromptMode ? [] : tools;

      const result: StreamResult = await nonStreamCompletion(
        this.client,
        this.model.id,
        currentMessages,
        temperature,
        maxTokens,
        {
          signal: abortSignal,
          enableTools: !usePromptMode && tools.length > 0,
          mcpTools,
          mcpMode,
          model: this.model,
          tools: streamTools,
          extraBody
        }
      );

      // å‘é€æ¨ç†å—
      if (result.reasoning && onChunk) {
        onChunk({
          type: ChunkType.THINKING_COMPLETE,
          text: result.reasoning,
          thinking_millsec: result.reasoningTime || 0
        });
        allReasoningParts.push(result.reasoning);
      }

      const content = result.content;
      const nativeToolCalls = result.nativeToolCalls;
      let toolResults: any[] = [];
      let hasCompletion = false;

      // å¤„ç†å‡½æ•°è°ƒç”¨
      if (nativeToolCalls && nativeToolCalls.length > 0 && mcpTools.length > 0) {
        if (onChunk) {
          onChunk({ type: ChunkType.TEXT_COMPLETE, text: content || '' });
        }

        // å‡½æ•°è°ƒç”¨æ¨¡å¼ï¼šä½¿ç”¨ AI SDK æœŸæœ›çš„ AssistantModelMessage æ ¼å¼
        const toolCallParts = nativeToolCalls.map((tc: any) => {
          let input = tc.function?.arguments || tc.args || {};
          if (typeof input === 'string') {
            try {
              input = JSON.parse(input);
            } catch {
              input = {};
            }
          }
          return {
            type: 'tool-call' as const,
            toolCallId: tc.id || tc.toolCallId,
            toolName: tc.function?.name || tc.name || tc.toolName,
            input
          };
        });
        
        const assistantContent = content 
          ? [{ type: 'text' as const, text: content }, ...toolCallParts]
          : toolCallParts;
        
        currentMessages.push({
          role: 'assistant',
          content: assistantContent
        });

        const callResult = await this.processToolCalls(nativeToolCalls, mcpTools, onChunk);
        toolResults = callResult.messages;
        hasCompletion = callResult.hasCompletion;
      }

      // å¤„ç† XML å·¥å…·è°ƒç”¨
      if (content && mcpTools.length > 0) {
        const textWithoutTools = removeToolUseTags(content);
        const hasToolTags = textWithoutTools.length < content.length;

        if (hasToolTags) {
          if (textWithoutTools.trim() && onChunk) {
            onChunk({ type: ChunkType.TEXT_COMPLETE, text: textWithoutTools });
          }

          currentMessages.push({ role: 'assistant', content });

          const xmlResult = await this.processToolUses(content, mcpTools, onChunk);
          toolResults = toolResults.concat(xmlResult.messages);
          hasCompletion = hasCompletion || xmlResult.hasCompletion;
        }
      }

      if (hasCompletion) {
        if (toolResults.length > 0) {
          currentMessages.push(...toolResults);
        }
        break;
      }

      if (toolResults.length > 0) {
        currentMessages.push(...toolResults);
        continue;
      }

      // å‘é€æœ€ç»ˆæ–‡æœ¬
      if (onChunk) {
        onChunk({ type: ChunkType.TEXT_COMPLETE, text: content || '' });
      }

      // è¿”å›ç»“æœ
      const finalReasoning = allReasoningParts.length > 0
        ? allReasoningParts.join('\n\n---\n\n')
        : undefined;

      if (finalReasoning) {
        return { content, reasoning: finalReasoning, reasoningTime: 0 };
      }
      return content;
    }

    return '';
  }

  /**
   * æ ¼å¼åŒ–ç»“æœ
   */
  private formatResult(result: StreamResult): string | { content: string; reasoning?: string; reasoningTime?: number } {
    if (result.reasoning) {
      return {
        content: result.content,
        reasoning: result.reasoning,
        reasoningTime: result.reasoningTime
      };
    }
    return result.content;
  }
}

// å¯¼å‡º
export { BaseOpenAIAISDKProvider as BaseOpenAIProvider };
