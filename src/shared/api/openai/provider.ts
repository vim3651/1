/**
 * OpenAI Provider
 * è´Ÿè´£ä¸OpenAI APIé€šä¿¡
 */
import OpenAI from 'openai';
import { createClient } from './client';
import { unifiedStreamCompletion } from './unifiedStreamProcessor';
import { UnifiedParameterManager } from '../parameters/UnifiedParameterManager';
import { OpenAIParameterFormatter } from '../parameters/formatters';

import {
  supportsMultimodal,
  supportsWebSearch,
  getWebSearchParams
} from './client';

import {
  isReasoningModel
} from '../../../config/models';
import { AbstractBaseProvider } from '../baseProvider';
import type { Message, Model, MCPTool, MCPToolResponse, MCPCallToolResponse } from '../../types';
import { parseAndCallTools, parseToolUse, removeToolUseTags } from '../../utils/mcpToolParser';
import {
  convertMcpToolsToOpenAI,
  mcpToolCallResponseToOpenAIMessage,
  convertToolCallsToMcpResponses
} from './tools';
import { ChunkType } from '../../types/chunk';



/**
 * åŸºç¡€OpenAI Provider
 */
export abstract class BaseOpenAIProvider extends AbstractBaseProvider {
  protected client: OpenAI;
  protected parameterManager: UnifiedParameterManager;

  constructor(model: Model) {
    super(model);
    this.client = createClient(model);
    this.parameterManager = new UnifiedParameterManager({ model, providerType: 'openai' });
  }

  /**
   * å°† MCP å·¥å…·è½¬æ¢ä¸º OpenAI å·¥å…·æ ¼å¼
   */
  public convertMcpTools<T>(mcpTools: MCPTool[]): T[] {
    return convertMcpToolsToOpenAI<T>(mcpTools);
  }

  /**
   * æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒå¤šæ¨¡æ€
   * @param model æ¨¡å‹å¯¹è±¡ï¼ˆå¯é€‰ï¼‰
   * @returns æ˜¯å¦æ”¯æŒå¤šæ¨¡æ€
   * @remarks æ­¤æ–¹æ³•ä¸ºå­ç±»æä¾›é‡å†™å…¥å£ï¼Œå†…éƒ¨å§”æ‰˜ç»™ client.supportsMultimodal
   */
  protected supportsMultimodal(model?: Model): boolean {
    const actualModel = model || this.model;
    return supportsMultimodal(actualModel);
  }

  /**
   * æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒç½‘é¡µæœç´¢
   * @remarks æ­¤æ–¹æ³•ä¸ºå­ç±»æä¾›é‡å†™å…¥å£ï¼Œå†…éƒ¨å§”æ‰˜ç»™ client.supportsWebSearch
   */
  protected supportsWebSearch(): boolean {
    return supportsWebSearch(this.model);
  }

  /**
   * æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒæ¨ç†ä¼˜åŒ–
   * @remarks æ­¤æ–¹æ³•ä¸ºå­ç±»æä¾›é‡å†™å…¥å£ï¼Œå†…éƒ¨å§”æ‰˜ç»™ isReasoningModel
   */
  protected supportsReasoning(): boolean {
    // ä½¿ç”¨å¯¼å…¥çš„æ¨¡å‹æ£€æµ‹å‡½æ•°
    return isReasoningModel(this.model);
  }

  /**
   * è·å–ç»Ÿä¸€å‚æ•°å¹¶è½¬æ¢ä¸º OpenAI API æ ¼å¼
   */
  protected getApiParams(assistant?: any): {
    unified: ReturnType<UnifiedParameterManager['getUnifiedParameters']>;
    apiParams: Record<string, any>;
  } {
    if (assistant) {
      this.parameterManager.updateAssistant(assistant);
    }
    const unified = this.parameterManager.getUnifiedParameters(isReasoningModel(this.model));
    const { customParameters, ...standardParams } = unified;
    const apiParams = OpenAIParameterFormatter.toAPIFormat(standardParams, this.model);
    
    // ğŸ†• åˆå¹¶è‡ªå®šä¹‰å‚æ•°åˆ° API è¯·æ±‚
    const finalParams = {
      ...apiParams,
      ...customParameters, // è‡ªå®šä¹‰å‚æ•°ç›´æ¥å±•å¼€åˆ°è¯·æ±‚ä¸­
    };
    
    return { unified, apiParams: finalParams };
  }



  /**
   * å‡†å¤‡APIæ¶ˆæ¯æ ¼å¼
   * å°†ä¸šåŠ¡æ¶ˆæ¯è½¬æ¢ä¸ºAPIæ ¼å¼
   */
  protected async prepareAPIMessages(messages: Message[], systemPrompt?: string, mcpTools?: MCPTool[]): Promise<any[]> {
    const apiMessages = [];

    // è·å–å·¥ä½œåŒºåˆ—è¡¨ï¼ˆç”¨äºæ³¨å…¥åˆ°ç³»ç»Ÿæç¤ºè¯ï¼‰
    const workspaces = mcpTools && mcpTools.length > 0 ? await this.getWorkspaces() : [];

    // æ·»åŠ ç³»ç»Ÿæç¤º
    const finalSystemPrompt = this.buildSystemPromptWithTools(systemPrompt || '', mcpTools, workspaces);
    if (finalSystemPrompt.trim()) {
      apiMessages.push({
        role: 'system',
        content: finalSystemPrompt
      });
    }

    // å¤„ç†ç”¨æˆ·å’ŒåŠ©æ‰‹æ¶ˆæ¯ï¼ˆè·³è¿‡ system æ¶ˆæ¯ï¼Œå› ä¸ºå·²é€šè¿‡ buildSystemPromptWithTools åˆå¹¶ï¼‰
    for (const message of messages) {
      // è·³è¿‡ system æ¶ˆæ¯ï¼Œé¿å…é‡å¤
      if (message.role === 'system') {
        continue;
      }
      try {
        const content = (message as any).content;
        if (content !== undefined) {
          apiMessages.push({
            role: message.role,
            content: content
          });
        }
      } catch (error) {
        console.error(`[OpenAIProvider] å¤„ç†æ¶ˆæ¯å¤±è´¥:`, error);
        // é™çº§å¤„ç†
        const content = (message as any).content;
        if (content && typeof content === 'string' && content.trim()) {
          apiMessages.push({
            role: message.role,
            content: content
          });
        }
      }
    }

    // ç¡®ä¿è‡³å°‘æœ‰ä¸€æ¡æ¶ˆæ¯
    if (apiMessages.length === 0 || !apiMessages.some(msg => msg.role === 'user')) {
      apiMessages.push({
        role: 'user',
        content: 'ä½ å¥½'
      });
    }

    return apiMessages;
  }

  /**
   * æµ‹è¯•APIè¿æ¥
   */
  public async testConnection(): Promise<boolean> {
    try {
      const { apiParams } = this.getApiParams();

      const response = await this.client.chat.completions.create({
        model: this.model.id,
        messages: [{ role: 'user', content: 'Hello' }],
        max_tokens: 5,
        temperature: apiParams.temperature,
        stream: false
      });
      return Boolean(response.choices[0].message);
    } catch (error) {
      console.error('APIè¿æ¥æµ‹è¯•å¤±è´¥:', error);
      return false;
    }
  }

  /**
   * å°† MCP å·¥å…·è°ƒç”¨å“åº”è½¬æ¢ä¸ºæ¶ˆæ¯æ ¼å¼
   */
  public mcpToolCallResponseToMessage(
    mcpToolResponse: MCPToolResponse,
    resp: MCPCallToolResponse,
    model: Model
  ): any {
    return mcpToolCallResponseToOpenAIMessage(mcpToolResponse, resp, model);
  }

  /**
   * å°†å·¥å…·è°ƒç”¨è½¬æ¢ä¸º MCP å·¥å…·å“åº”
   */
  protected convertToolCallsToMcpResponses(
    toolCalls: any[],
    mcpTools: MCPTool[]
  ): MCPToolResponse[] {
    return convertToolCallsToMcpResponses(toolCalls, mcpTools);
  }





  /** æ£€æµ‹å·¥å…·åˆ—è¡¨æ˜¯å¦åŒ…å« attempt_completionï¼ˆæ”¯æŒå¸¦å‰ç¼€çš„åç§°ï¼‰ */
  private hasCompletionTool(toolNames: string[]): boolean {
    return toolNames.some(name => 
      name === 'attempt_completion' || name.endsWith('-attempt_completion')
    );
  }

  /**
   * å¤„ç†å·¥å…·è°ƒç”¨ï¼ˆFunction Calling æ¨¡å¼ï¼‰
   */
  protected async processToolCalls(
    toolCalls: any[],
    mcpTools: MCPTool[],
    onChunk?: (chunk: import('../../types/chunk').Chunk) => void | Promise<void>
  ): Promise<{ messages: any[]; hasCompletion: boolean }> {
    if (!toolCalls?.length) return { messages: [], hasCompletion: false };

    const toolNames = toolCalls.map(tc => tc.function?.name || tc.name || '');
    const hasCompletion = this.hasCompletionTool(toolNames);
    
    console.log(`[OpenAI] å¤„ç† ${toolCalls.length} ä¸ªå·¥å…·è°ƒç”¨${hasCompletion ? 'ï¼ˆå« attempt_completionï¼‰' : ''}`);

    const mcpToolResponses = this.convertToolCallsToMcpResponses(toolCalls, mcpTools);
    const results = await parseAndCallTools(mcpToolResponses, mcpTools, onChunk);
    const messages = results
      .map((result, i) => this.mcpToolCallResponseToMessage(mcpToolResponses[i], result, this.model))
      .filter(Boolean);

    return { messages, hasCompletion };
  }

  /**
   * å¤„ç†å·¥å…·ä½¿ç”¨ï¼ˆXML æç¤ºè¯æ¨¡å¼ï¼‰
   */
  protected async processToolUses(
    content: string,
    mcpTools: MCPTool[],
    onChunk?: (chunk: import('../../types/chunk').Chunk) => void | Promise<void>
  ): Promise<{ messages: any[]; hasCompletion: boolean }> {
    if (!content || !mcpTools?.length) return { messages: [], hasCompletion: false };

    const toolResponses = parseToolUse(content, mcpTools);
    if (!toolResponses.length) return { messages: [], hasCompletion: false };

    const toolNames = toolResponses.map(tr => tr.tool?.name || tr.tool?.id || '');
    const hasCompletion = this.hasCompletionTool(toolNames);
    
    console.log(`[OpenAI] å¤„ç† ${toolResponses.length} ä¸ª XML å·¥å…·è°ƒç”¨${hasCompletion ? 'ï¼ˆå« attempt_completionï¼‰' : ''}`);

    const results = await parseAndCallTools(content, mcpTools, onChunk);
    const messages: any[] = [];
    
    for (let i = 0; i < Math.min(results.length, toolResponses.length); i++) {
      const msg = this.mcpToolCallResponseToMessage(toolResponses[i], results[i], this.model);
      if (msg) messages.push(msg);
    }

    return { messages, hasCompletion };
  }

  /**
   * æŠ½è±¡æ–¹æ³•ï¼šå‘é€èŠå¤©æ¶ˆæ¯
   */
  public abstract sendChatMessage(
    messages: Message[],
    options?: {
      onChunk?: (chunk: import('../../types/chunk').Chunk) => void | Promise<void>;
      enableWebSearch?: boolean;
      systemPrompt?: string;
      enableTools?: boolean;
      mcpTools?: import('../../types').MCPTool[];
      mcpMode?: 'prompt' | 'function';
      abortSignal?: AbortSignal;
      assistant?: any;
    }
  ): Promise<string | { content: string; reasoning?: string; reasoningTime?: number }>;
}

/**
 * OpenAI Providerå®ç°ç±»
 */
export class OpenAIProvider extends BaseOpenAIProvider {
  constructor(model: Model) {
    super(model);
  }

  /**
   * å‘é€èŠå¤©æ¶ˆæ¯ - åº•å±‚APIè°ƒç”¨
   * ä¸“æ³¨äºAPIè°ƒç”¨ï¼Œä¸šåŠ¡é€»è¾‘ç”±chat.tså¤„ç†
   * @param messages æ¶ˆæ¯æ•°ç»„
   * @param options é€‰é¡¹
   * @returns å“åº”å†…å®¹
   */
  public async sendChatMessage(
    messages: Message[],
    options?: {
      onChunk?: (chunk: import('../../types/chunk').Chunk) => void | Promise<void>;
      enableWebSearch?: boolean;
      systemPrompt?: string;
      enableTools?: boolean;
      mcpTools?: import('../../types').MCPTool[];
      mcpMode?: 'prompt' | 'function';
      abortSignal?: AbortSignal;
      assistant?: any;
    }
  ): Promise<string | { content: string; reasoning?: string; reasoningTime?: number }> {
    console.log(`[OpenAIProvider] å¼€å§‹APIè°ƒç”¨, æ¨¡å‹: ${this.model.id}`);

    const {
      onChunk,
      enableWebSearch = false,
      systemPrompt = '',
      enableTools = true,
      mcpTools = [],
      mcpMode = 'function',
      abortSignal,
      assistant
    } = options || {};

    // å‡†å¤‡APIæ¶ˆæ¯æ ¼å¼ï¼ˆå¼‚æ­¥è·å–å·¥ä½œåŒºä¿¡æ¯ï¼‰
    const apiMessages = await this.prepareAPIMessages(messages, systemPrompt, mcpTools);

    // é…ç½®å·¥å…·
    const { tools } = this.setupToolsConfig({
      mcpTools,
      model: this.model,
      enableToolUse: enableTools,
      mcpMode
    });

    // è·å–ç»Ÿä¸€å‚æ•°ä¸ API æ ¼å¼å‚æ•°
    const { unified, apiParams } = this.getApiParams(assistant);
    const streamEnabled = unified.stream ?? true;

    // æ„å»ºè¯·æ±‚å‚æ•°
    const requestParams: any = {
      model: this.model.id,
      messages: apiMessages,
      stream: streamEnabled,
      ...apiParams
    };

    // æ·»åŠ å·¥å…·
    if (enableTools && tools.length > 0 && !this.getUseSystemPromptForTools()) {
      requestParams.tools = tools;
    }


    // æ£€æŸ¥APIå¯†é’¥å’ŒåŸºç¡€URLæ˜¯å¦è®¾ç½®
    if (!this.model.apiKey) {
      console.error('[OpenAIProvider.sendChatMessage] é”™è¯¯: APIå¯†é’¥æœªè®¾ç½®');
      throw new Error('APIå¯†é’¥æœªè®¾ç½®ï¼Œè¯·åœ¨è®¾ç½®ä¸­é…ç½®OpenAI APIå¯†é’¥');
    }

    if (!this.model.baseUrl) {
      console.warn('[OpenAIProvider.sendChatMessage] è­¦å‘Š: åŸºç¡€URLæœªè®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼');
    }

    // æ·»åŠ ç½‘é¡µæœç´¢å‚æ•°
    if (enableWebSearch && this.supportsWebSearch()) {
      Object.assign(requestParams, getWebSearchParams(this.model, enableWebSearch));
    }

    try {
      // æ ¹æ®æµå¼è¾“å‡ºè®¾ç½®é€‰æ‹©å“åº”å¤„ç†æ–¹å¼
      if (streamEnabled) {
        return await this.handleStreamResponse(requestParams, {
          onChunk,
          enableTools,
          mcpTools,
          abortSignal
        });
      } else {
        // éæµå¼å“åº”å¤„ç†
        return await this.handleNonStreamResponse(requestParams, onChunk, enableTools, mcpTools, abortSignal);
      }
    } catch (error: any) {
      // æ£€æŸ¥æ˜¯å¦ä¸ºä¸­æ–­é”™è¯¯
      if (error?.name === 'AbortError' || error?.message?.includes('aborted')) {
        console.log('[OpenAIProvider.sendChatMessage] è¯·æ±‚è¢«ç”¨æˆ·ä¸­æ–­');
        throw new DOMException('Operation aborted', 'AbortError');
      }

      // æ£€æŸ¥æ˜¯å¦ä¸ºå‚æ•°é”™è¯¯ï¼Œæä¾›å‹å¥½çš„é”™è¯¯ä¿¡æ¯
      if (error?.status === 400 && error?.message?.includes('max_tokens')) {
        const modelName = this.model.name || this.model.id;
        const currentMaxTokens = requestParams.max_tokens;
        console.error(`[OpenAIProvider] ${modelName} æ¨¡å‹çš„ max_tokens å‚æ•°è¶…å‡ºé™åˆ¶: ${currentMaxTokens}`);
        throw new Error(`æ¨¡å‹ ${modelName} ä¸æ”¯æŒå½“å‰çš„æœ€å¤§è¾“å‡ºtokenè®¾ç½® (${currentMaxTokens})ã€‚è¯·åœ¨æ¨¡å‹è®¾ç½®ä¸­é™ä½æœ€å¤§è¾“å‡ºtokenæ•°é‡ã€‚`);
      }

      console.error('[OpenAIProvider.sendChatMessage] APIè¯·æ±‚å¤±è´¥:', error);
      throw error;
    }
  }



  /**
   * å¤„ç†æµå¼å“åº”ï¼ˆç»Ÿä¸€æ–¹æ³•ï¼‰
   * åˆå¹¶äº†åŸæœ‰çš„ handleStreamResponse å’Œ handleStreamResponseWithoutCallback
   * @param params è¯·æ±‚å‚æ•°
   * @param options é€‰é¡¹
   * @returns å“åº”å†…å®¹
   */
  private async handleStreamResponse(
    params: any,
    options: {
      onChunk?: (chunk: import('../../types/chunk').Chunk) => void | Promise<void>;
      enableTools?: boolean;
      mcpTools?: import('../../types').MCPTool[];
      abortSignal?: AbortSignal;
    } = {}
  ): Promise<string | { content: string; reasoning?: string; reasoningTime?: number }> {
    const {
      onChunk,
      enableTools = true,
      mcpTools = [],
      abortSignal
    } = options;

    try {
      // å·¥å…·è°ƒç”¨å¾ªç¯å¤„ç†
      let currentMessages = [...params.messages];
      let iteration = 0;

      while (true) {
        iteration++;
        console.log(`[OpenAIProvider] æµå¼å·¥å…·è°ƒç”¨è¿­ä»£ ${iteration}`);

        // å‡†å¤‡è¯·æ±‚å‚æ•°
        const iterationParams = {
          ...params,
          messages: currentMessages,
          signal: abortSignal
        };

        // åœ¨æç¤ºè¯æ¨¡å¼ä¸‹ï¼Œç§»é™¤ tools å‚æ•°é¿å…å†²çª
        if (this.getUseSystemPromptForTools()) {
          delete iterationParams.tools;
          delete iterationParams.tool_choice;
          console.log(`[OpenAIProvider] æç¤ºè¯æ¨¡å¼ï¼šç§»é™¤ API ä¸­çš„ tools å‚æ•°`);
        }

        // æ„å»ºæµå‚æ•°
        const streamParams = {
          ...iterationParams,
          enableTools,
          mcpTools
        };

        const result = await unifiedStreamCompletion(
          this.client,
          this.model.id,
          currentMessages,
          params.temperature,
          params.max_tokens || params.max_completion_tokens,
          streamParams,
          onChunk
        );

        console.log(`[OpenAIProvider] æµå¼å“åº”ç»“æœç±»å‹: ${typeof result}, hasToolCalls: ${typeof result === 'object' && (result as any)?.hasToolCalls}`);

        // æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨æ ‡è®°
        if (typeof result === 'object' && (result as any).hasToolCalls) {
          console.log(`[OpenAIProvider] æµå¼å“åº”æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨`);

          const content = result.content;
          const nativeToolCalls = (result as any).nativeToolCalls;
          const usePromptMode = this.getUseSystemPromptForTools();

          // æ ¹æ®ç”¨æˆ·è®¾ç½®å†³å®šå·¥å…·è°ƒç”¨æ–¹å¼
          if (usePromptMode) {
            // æç¤ºè¯æ³¨å…¥æ¨¡å¼ï¼šä½¿ç”¨ XML æ ¼å¼å·¥å…·è°ƒç”¨
            console.log(`[OpenAIProvider] æç¤ºè¯æ³¨å…¥æ¨¡å¼ï¼šå¤„ç† XML æ ¼å¼å·¥å…·è°ƒç”¨`);
            const { messages: xmlToolResults, hasCompletion } = await this.processToolUses(content, mcpTools, onChunk);

            if (xmlToolResults.length > 0) {
              // ä¿ç•™å®Œæ•´å†…å®¹ï¼ˆåŒ…å«å·¥å…·è°ƒç”¨ï¼‰ï¼Œè®©æ¨¡å‹çŸ¥é“è‡ªå·±è°ƒç”¨äº†ä»€ä¹ˆå·¥å…·
              console.log(`[OpenAIProvider] æµå¼ï¼šå¯¹è¯å†å²ä¿ç•™å®Œæ•´å†…å®¹ï¼ˆå«å·¥å…·è°ƒç”¨ï¼‰ï¼Œé•¿åº¦: ${content.length}`);

              // æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å¯¹è¯å†å²ï¼ˆä¿ç•™å·¥å…·è°ƒç”¨æ ‡ç­¾ï¼‰
              currentMessages.push({
                role: 'assistant',
                content: content
              });

              // æ·»åŠ å·¥å…·ç»“æœåˆ°å¯¹è¯å†å²
              currentMessages.push(...xmlToolResults);

              // æ£€æµ‹åˆ° attempt_completion æ—¶æå‰é€€å‡º
              if (hasCompletion) {
                console.log(`[OpenAIProvider] æ£€æµ‹åˆ° attempt_completionï¼Œè¿”å›ç»“æœè®©ä¸Šå±‚å¤„ç†ç»ˆæ­¢`);
                return result;
              }

              console.log(`[OpenAIProvider] æµå¼ XML å·¥å…·è°ƒç”¨å®Œæˆï¼Œç»§ç»­ä¸‹ä¸€è½®å¯¹è¯`);
              continue;
            }
          } else {
            // å‡½æ•°è°ƒç”¨æ¨¡å¼ï¼šä½¿ç”¨åŸç”Ÿ Function Calling
            if (nativeToolCalls && nativeToolCalls.length > 0) {
              console.log(`[OpenAIProvider] å‡½æ•°è°ƒç”¨æ¨¡å¼ï¼šæ£€æµ‹åˆ° ${nativeToolCalls.length} ä¸ªåŸç”Ÿå·¥å…·è°ƒç”¨`);

              // æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å¯¹è¯å†å²ï¼ˆåŒ…å« tool_callsï¼‰
              currentMessages.push({
                role: 'assistant',
                content: content || '',
                tool_calls: nativeToolCalls
              });

              // å¤„ç†åŸç”Ÿå·¥å…·è°ƒç”¨ï¼Œä¼ é€’ onChunk ä»¥æ›´æ–° UI
              const { messages: toolResults, hasCompletion } = await this.processToolCalls(nativeToolCalls, mcpTools, onChunk);

              if (toolResults.length > 0) {
                // æ·»åŠ å·¥å…·ç»“æœåˆ°å¯¹è¯å†å²
                currentMessages.push(...toolResults);

                // å¦‚æœæ£€æµ‹åˆ° attempt_completionï¼Œç»“æŸå¾ªç¯
                if (hasCompletion) {
                  console.log(`[OpenAIProvider] attempt_completion å·²æ‰§è¡Œï¼Œç»“æŸå·¥å…·è°ƒç”¨å¾ªç¯`);
                  return result;
                }

                console.log(`[OpenAIProvider] æµå¼åŸç”Ÿå·¥å…·è°ƒç”¨å®Œæˆï¼Œç»§ç»­ä¸‹ä¸€è½®å¯¹è¯`);
                continue;
              }
            }
          }
        }

        // æ²¡æœ‰å·¥å…·è°ƒç”¨æˆ–å·¥å…·è°ƒç”¨å¤„ç†å®Œæˆï¼Œè¿”å›ç»“æœ
        return result;
      }
    } catch (error) {
      console.error('[OpenAIProvider] æµå¼è¯·æ±‚å¤±è´¥:', error);
      throw error;
    }
  }

  /**
   * å¤„ç†éæµå¼å“åº”
   * 
   * ============= éæµå¼è¾“å‡ºé“¾è·¯ =============
   * while (iteration < maxIterations) {
   *   1. å‘é€ THINKING_COMPLETE (å…¨é‡ reasoning) â†’ åˆ›å»º/æ›´æ–°æ€è€ƒå—
   *   2. å¤„ç†å‡½æ•°è°ƒç”¨æ¨¡å¼ (toolCalls):
   *      - å‘é€ TEXT_COMPLETE â†’ åˆ›å»ºæ–‡æœ¬å—
   *      - è°ƒç”¨å·¥å…· â†’ åˆ›å»ºå·¥å…·å—
   *   3. å¤„ç† XML æ ¼å¼å·¥å…· (processToolUses):
   *      - å…ˆå‘é€ TEXT_COMPLETE (å»é™¤å·¥å…·æ ‡ç­¾åçš„æ–‡æœ¬) â†’ åˆ›å»ºæ–‡æœ¬å—
   *      - å†è°ƒç”¨å·¥å…· â†’ åˆ›å»ºå·¥å…·å—
   *   4. æœ‰å·¥å…·ç»“æœ â†’ continue ä¸‹ä¸€è½®
   *   5. æ— å·¥å…·ç»“æœ â†’ å‘é€æœ€ç»ˆ TEXT_COMPLETE â†’ break
   * }
   * 
   * ============= å…³é”®è®¾è®¡ =============
   * - æ‰€æœ‰ onChunk è°ƒç”¨éƒ½ awaitï¼Œç¡®ä¿å—åˆ›å»ºå®Œæˆåå†ç»§ç»­
   * - åªå‘ COMPLETEï¼Œä¸å‘ DELTAï¼ˆéæµå¼æ˜¯å…¨é‡æ•°æ®ï¼‰
   * - å…ˆå‘æ–‡æœ¬å†å‘å·¥å…·ï¼Œä¿è¯å—é¡ºåºæ­£ç¡®
   * - æ¯è½®çš„ reasoning ç‹¬ç«‹æ”¶é›†ï¼Œæœ€ååˆå¹¶è¿”å›
   */
  private async handleNonStreamResponse(
    params: any,
    onChunk?: (chunk: import('../../types/chunk').Chunk) => void | Promise<void>,
    enableTools: boolean = true,
    mcpTools: import('../../types').MCPTool[] = [],
    abortSignal?: AbortSignal
  ): Promise<string | { content: string; reasoning?: string; reasoningTime?: number }> {
    try {
      let currentMessages = [...params.messages];
      let finalContent = '';
      let allReasoningParts: string[] = []; // æ”¶é›†æ‰€æœ‰è½®æ¬¡çš„ reasoning
      let maxIterations = 5;
      let iteration = 0;

      while (iteration < maxIterations) {
        iteration++;

        const currentRequestParams = {
          ...params,
          messages: currentMessages,
          stream: false, // ç¡®ä¿æ˜¯éæµå¼
          signal: abortSignal // ä¼ é€’ä¸­æ–­ä¿¡å·
        };

        const response = await this.client.chat.completions.create(currentRequestParams);
        const choice = response.choices?.[0];
        if (!choice) {
          throw new Error('APIå“åº”ä¸­æ²¡æœ‰é€‰æ‹©é¡¹');
        }

        const content = choice.message?.content || '';
        // å¯¹äºæ¨ç†æ¨¡å‹ï¼Œå°è¯•ä»å¤šä¸ªå¯èƒ½çš„å­—æ®µä¸­è·å–æ¨ç†å†…å®¹
        const reasoning = (choice.message as any)?.reasoning ||
                         (choice.message as any)?.reasoning_content ||
                         undefined;

        // ç¬¬1æ­¥ï¼šå‘é€æ¨ç†å—ï¼ˆéæµå¼ç›´æ¥å‘ COMPLETEï¼‰
        if (reasoning && onChunk) {
          await onChunk({
            type: ChunkType.THINKING_COMPLETE,
            text: reasoning,
            thinking_millsec: 0
          });
          allReasoningParts.push(reasoning);
        }

        finalContent = content;

        // ç¬¬2æ­¥ï¼šå¤„ç†å‡½æ•°è°ƒç”¨æ¨¡å¼çš„å·¥å…·
        const toolCalls = choice.message?.tool_calls;
        let toolResults: any[] = [];
        let hasCompletion = false;

        if (toolCalls && toolCalls.length > 0 && enableTools && mcpTools.length > 0) {
          // åœ¨å·¥å…·è°ƒç”¨å‰å‘é€æ–‡æœ¬å—
          if (onChunk) {
            await onChunk({
              type: ChunkType.TEXT_COMPLETE,
              text: content || ''
            });
          }

          currentMessages.push({
            role: 'assistant',
            content: content || '',
            tool_calls: toolCalls
          });

          // å¤„ç†å·¥å…·è°ƒç”¨
          const result = await this.processToolCalls(toolCalls, mcpTools, onChunk);
          toolResults = result.messages;
          hasCompletion = result.hasCompletion;
        }

        // ç¬¬3æ­¥ï¼šå¤„ç† XML æ ¼å¼çš„å·¥å…·è°ƒç”¨ï¼ˆæç¤ºè¯æ¨¡å¼ï¼‰
        if (content && content.length > 0 && enableTools && mcpTools.length > 0) {
          const textWithoutTools = removeToolUseTags(content);
          const hasToolTags = textWithoutTools.length < content.length;
          
          if (hasToolTags) {
            // å…ˆå‘é€å»é™¤å·¥å…·æ ‡ç­¾åçš„æ–‡æœ¬ï¼ˆç”¨äº UI æ˜¾ç¤ºï¼‰
            if (textWithoutTools.trim() && onChunk) {
              await onChunk({
                type: ChunkType.TEXT_COMPLETE,
                text: textWithoutTools
              });
            }
            finalContent = textWithoutTools;
            
            // æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å¯¹è¯å†å²ï¼ˆä¿ç•™å®Œæ•´å†…å®¹ï¼ŒåŒ…å«å·¥å…·è°ƒç”¨æ ‡ç­¾ï¼‰
            currentMessages.push({
              role: 'assistant',
              content: content  // ä¿ç•™å·¥å…·è°ƒç”¨æ ‡ç­¾ï¼Œè®©æ¨¡å‹çŸ¥é“è‡ªå·±è°ƒç”¨äº†ä»€ä¹ˆ
            });
          }
          
          // ç„¶åå¤„ç†å·¥å…·è°ƒç”¨
          const xmlResult = await this.processToolUses(content, mcpTools, onChunk);
          toolResults = toolResults.concat(xmlResult.messages);
          hasCompletion = hasCompletion || xmlResult.hasCompletion;
        }

        // å¦‚æœæ£€æµ‹åˆ° attempt_completionï¼Œç»“æŸå¾ªç¯
        if (hasCompletion) {
          console.log(`[OpenAIProvider] éæµå¼ï¼šattempt_completion å·²æ‰§è¡Œï¼Œç»“æŸå·¥å…·è°ƒç”¨å¾ªç¯`);
          if (toolResults.length > 0) {
            currentMessages.push(...toolResults);
          }
          break;
        }

        if (toolResults.length > 0) {
          currentMessages.push(...toolResults);
          continue; // ç»§ç»­ä¸‹ä¸€è½®
        } else {
          // æœ€åä¸€è½®æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œå‘é€æœ€ç»ˆæ–‡æœ¬å—
          if (onChunk) {
            await onChunk({
              type: ChunkType.TEXT_COMPLETE,
              text: content || ''
            });
          }
          break;
        }
      }

      // è¿”å›ç»“æœ - åˆå¹¶æ‰€æœ‰è½®æ¬¡çš„ reasoning
      const finalReasoning = allReasoningParts.length > 0 
        ? allReasoningParts.join('\n\n---\n\n') 
        : undefined;

      if (finalReasoning) {
        return {
          content: finalContent,
          reasoning: finalReasoning,
          reasoningTime: 0 // éæµå¼å“åº”æ²¡æœ‰æ¨ç†æ—¶é—´
        };
      } else {
        return finalContent;
      }
    } catch (error) {
      console.error('[OpenAIProvider.handleNonStreamResponse] éæµå¼APIè¯·æ±‚å¤±è´¥:', error);
      throw error;
    }
  }
}
