# å½“å‰æµå¼è¾“å‡ºæ¶æ„åˆ†æ

> è¯¦ç»†è®°å½•å½“å‰é¡¹ç›®çš„æµå¼/éæµå¼è¾“å‡ºé“¾è·¯

## ğŸ“Š æ•´ä½“æ¶æ„å›¾

```
ç”¨æˆ·å‘é€æ¶ˆæ¯
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å…¥å£å±‚                                                          â”‚
â”‚  MessageService.sendMessage()                                    â”‚
â”‚  src/shared/services/messages/messageService.ts                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Thunk å±‚                                                        â”‚
â”‚  sendMessage() â†’ processAssistantResponse()                      â”‚
â”‚  src/shared/store/thunks/message/sendMessage.ts                  â”‚
â”‚  src/shared/store/thunks/message/assistantResponse.ts            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Provider å±‚                                                 â”‚
â”‚  ApiProviderRegistry.get(model).sendChatMessage()               â”‚
â”‚  src/shared/services/messages/ApiProvider.ts                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OpenAI Provider å±‚                                              â”‚
â”‚  OpenAIProvider.sendChatMessage()                               â”‚
â”‚  src/shared/api/openai/provider.ts                              â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ getStreamOutputSetting() å†³å®šæµå¼/éæµå¼                  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€ streamEnabled = true â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                                      â”‚
      â–¼                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    æµå¼è¾“å‡ºé“¾è·¯           â”‚      â”‚    éæµå¼è¾“å‡ºé“¾è·¯         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸŒŠ æµå¼è¾“å‡ºè¯¦ç»†é“¾è·¯

### è°ƒç”¨æ ˆ

```
OpenAIProvider.sendChatMessage()
  â”‚
  â”œâ”€â”€ æœ‰ onUpdate: handleStreamResponse()         [provider.ts:542-639]
  â”‚         â”‚
  â”‚         â–¼
  â”‚   unifiedStreamCompletion()                   [unifiedStreamProcessor.ts:316-377]
  â”‚         â”‚
  â”‚         â–¼
  â”‚   UnifiedStreamProcessor.processStream()      [unifiedStreamProcessor.ts:98-117]
  â”‚         â”‚
  â”‚         â–¼
  â”‚   processAdvancedStream()                     [unifiedStreamProcessor.ts:122-154]
  â”‚         â”‚
  â”‚         â”œâ”€â”€ extractReasoningMiddleware()      [æå–æ¨ç†æ ‡ç­¾]
  â”‚         â”‚
  â”‚         â–¼
  â”‚   handleAdvancedChunk()                       [unifiedStreamProcessor.ts:161-263]
  â”‚         â”‚
  â”‚         â”œâ”€â”€ type: 'text-delta'    â†’ onChunk(TEXT_DELTA) / onUpdate()
  â”‚         â”œâ”€â”€ type: 'reasoning'     â†’ onChunk(THINKING_DELTA) / onUpdate()
  â”‚         â””â”€â”€ type: 'finish'        â†’ å‘é€å®Œæˆäº‹ä»¶
  â”‚
  â””â”€â”€ æ—  onUpdate: handleStreamResponseWithoutCallback() [provider.ts:651-747]
            â”‚
            â””â”€â”€ (ä¸ä¸Šé¢å‡ ä¹ç›¸åŒçš„é€»è¾‘)
```

### å…³é”®æ–‡ä»¶

| æ–‡ä»¶ | èŒè´£ | è¡Œå· |
|------|------|------|
| `provider.ts` | æµå¼å…¥å£åˆ¤æ–­ã€å·¥å…·è°ƒç”¨å¾ªç¯ | 476-482 |
| `provider.ts` | `handleStreamResponse` | 542-639 |
| `provider.ts` | `handleStreamResponseWithoutCallback` | 651-747 |
| `unifiedStreamProcessor.ts` | ç»Ÿä¸€æµå¤„ç†å™¨ | 65-311 |
| `streamUtils.ts` | Chunk è½¬æ¢å·¥å…· | 97-159 |

### æ•°æ®æµè½¬æ¢

```
OpenAI API Stream
      â”‚
      â–¼ (AsyncIterable<OpenAI.ChatCompletionChunk>)
      
openAIChunkToTextDelta()              [streamUtils.ts:97-159]
      â”‚
      â”œâ”€â”€ chunk.choices[0].delta.content â†’ { type: 'text-delta', textDelta }
      â””â”€â”€ chunk.choices[0].delta.reasoning_content â†’ { type: 'reasoning', textDelta }
      â”‚
      â–¼ (AsyncGenerator<OpenAIStreamChunk>)
      
extractReasoningMiddleware()          [æå–æ€è€ƒæ ‡ç­¾ <think>...</think>]
      â”‚
      â–¼ (ReadableStream)
      
UnifiedStreamProcessor.handleAdvancedChunk()
      â”‚
      â”œâ”€ text-delta  â”€â”€â†’  onChunk({ type: TEXT_DELTA, text })
      â”‚                   æˆ– onUpdate(content, '')
      â”‚
      â”œâ”€ reasoning   â”€â”€â†’  onChunk({ type: THINKING_DELTA, text })
      â”‚                   æˆ– onUpdate('', reasoning)
      â”‚
      â””â”€ finish      â”€â”€â†’  EventEmitter.emit(STREAM_COMPLETE)
```

---

## ğŸ“¦ éæµå¼è¾“å‡ºè¯¦ç»†é“¾è·¯

### è°ƒç”¨æ ˆ

```
OpenAIProvider.sendChatMessage()
      â”‚
      â–¼
handleNonStreamResponse()                     [provider.ts:759-905]
      â”‚
      â–¼
client.chat.completions.create({ stream: false })
      â”‚
      â–¼
ç›´æ¥è¿”å›å®Œæ•´å“åº”
      â”‚
      â”œâ”€â”€ æå– content = choice.message.content
      â”œâ”€â”€ æå– reasoning = choice.message.reasoning_content
      â”‚
      â–¼
onChunk() æˆ– onUpdate() å›è°ƒ
      â”‚
      â”œâ”€â”€ æœ‰æ€è€ƒå†…å®¹: onChunk({ type: THINKING_COMPLETE, text })
      â””â”€â”€ æœ‰æ–‡æœ¬å†…å®¹: onChunk({ type: TEXT_COMPLETE, text })
```

### å…³é”®ä»£ç 

```typescript
// provider.ts:759-905
private async handleNonStreamResponse(...) {
  // 1. è°ƒç”¨ API
  const response = await this.client.chat.completions.create({
    ...currentRequestParams,
    stream: false
  });

  // 2. æå–å†…å®¹
  const content = choice.message?.content || '';
  const reasoning = choice.message?.reasoning_content;

  // 3. å‘é€å›è°ƒ
  if (onChunk) {
    if (finalReasoning) {
      onChunk({ type: ChunkType.THINKING_COMPLETE, text: finalReasoning });
    }
    if (finalContent) {
      onChunk({ type: ChunkType.TEXT_COMPLETE, text: finalContent });
    }
  } else if (onUpdate) {
    // å…¼å®¹æ—§å›è°ƒ
    if (finalReasoning) onUpdate('', finalReasoning);
    if (finalContent) onUpdate(finalContent);
  }
}
```

---

## ğŸ”„ å“åº”å¤„ç†å±‚

### ResponseHandler æ¶æ„

```
provider å›è°ƒ
      â”‚
      â”œâ”€ onChunk()  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                       â–¼
      â””â”€ onUpdate() â”€â”€â†’ ResponseHandler.handleChunk() / handleStringContent()
                              â”‚
                              â–¼
                    ResponseChunkProcessor.handleChunk()
                    [responseHandlers/ResponseChunkProcessor.ts:180-207]
                              â”‚
                              â”œâ”€ TEXT_DELTA      â†’ TextAccumulator.accumulate()
                              â”œâ”€ TEXT_COMPLETE   â†’ TextAccumulator.accumulate()
                              â”œâ”€ THINKING_DELTA  â†’ ThinkingAccumulator.accumulate()
                              â””â”€ THINKING_COMPLETE â†’ ThinkingAccumulator.accumulate()
                              â”‚
                              â–¼
                    ThrottledBlockUpdater
                    [responseHandlers/ResponseChunkProcessor.ts:65-104]
                              â”‚
                              â”œâ”€ Redux State æ›´æ–° (èŠ‚æµ)
                              â””â”€ IndexedDB å­˜å‚¨ (èŠ‚æµ)
```

### handleStringContent æµç¨‹

```typescript
// ResponseHandler.ts:121-178
async handleStringContent(content: string, reasoning?: string) {
  // 1. æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦å·²å®Œæˆ
  if (message?.status === SUCCESS) return;

  // 2. æ£€æŸ¥å¯¹æ¯”ç»“æœ
  if (comparisonHandler.isComparisonResult(content, reasoning)) {
    comparisonHandler.handleComparisonResult(reasoning);
    return;
  }

  // 3. å¤„ç†æ¨ç†å†…å®¹
  if (reasoning?.trim()) {
    await this.handleChunk({ type: THINKING_DELTA, text: reasoning });
  } else {
    // 4. å°è¯• JSON è§£æ (å†—ä½™)
    try {
      const parsed = JSON.parse(content);
      if (parsed?.reasoning) { ... }
    } catch { }

    // 5. å¤„ç†æ–‡æœ¬å†…å®¹
    await this.handleChunk({ type: TEXT_DELTA, text: content });
  }
}
```

---

## âš ï¸ å½“å‰é—®é¢˜

### 1. åŒå›è°ƒå¹¶å­˜

```typescript
// assistantResponse.ts:369-388
response = await apiProvider.sendChatMessage(messagesToSend, {
  onUpdate: (content, reasoning) => {
    responseHandler.handleStringContent(content, reasoning);  // æ—§å›è°ƒ
  },
  onChunk: (chunk) => {
    responseHandler.handleChunk(chunk);  // æ–°å›è°ƒ
  },
});
```

**é—®é¢˜**: ä¸¤ä¸ªå›è°ƒå¯èƒ½åŒæ—¶è§¦å‘ï¼Œå¯¼è‡´é‡å¤å¤„ç†

### 2. æ–¹æ³•é‡å¤

```typescript
// provider.ts
handleStreamResponse()              // è¡Œ 542-639, ~100è¡Œ
handleStreamResponseWithoutCallback()  // è¡Œ 651-747, ~100è¡Œ

// 90% ç›¸åŒçš„ä»£ç 
```

### 3. æœªä½¿ç”¨çš„ä»£ç 

```typescript
// provider.ts:9
// import { createResponseHandler } from './responseHandler'; // æš‚æ—¶æ³¨é‡Šï¼Œå°†æ¥ä½¿ç”¨

// responseHandler.ts æ•´ä¸ªæ–‡ä»¶ 320 è¡Œæœªä½¿ç”¨
```

### 4. JSON è§£æå†—ä½™

```typescript
// ResponseHandler.ts:147-163
try {
  const parsed = JSON.parse(content);
  if (parsed?.reasoning) { ... }  // å‡ ä¹ä¸ä¼šè§¦å‘
} catch {
  // å¿½ç•¥
}
```

---

## ğŸ“‹ Chunk ç±»å‹å®šä¹‰

```typescript
// src/shared/types/chunk.ts
export enum ChunkType {
  TEXT_DELTA = 'text.delta',
  TEXT_COMPLETE = 'text.complete',
  THINKING_DELTA = 'thinking.delta',
  THINKING_COMPLETE = 'thinking.complete',
  MCP_TOOL_IN_PROGRESS = 'mcp_tool.in_progress',
  MCP_TOOL_COMPLETE = 'mcp_tool.complete',
  // ...
}

export interface Chunk {
  type: ChunkType;
  text?: string;
  thinking_millsec?: number;
  messageId?: string;
  blockId?: string;
  topicId?: string;
  // ...
}
```

---

## ğŸ”§ è®¾ç½®å¼€å…³

```typescript
// provider.ts:408
const streamEnabled = getStreamOutputSetting();

// ç”¨æˆ·è®¾ç½®æ§åˆ¶
// localStorage: 'stream-output-enabled' 
```
